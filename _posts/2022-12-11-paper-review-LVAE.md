---
layout: post
title: "[ë…¼ë¬¸ë¦¬ë·°] Linear Variational Autoencoder for Top-N Recommendation (IEEE, 2022)"
date: 2022-12-11
categories:
- Recommender System
tags:
- paper review
- recommender system
- variational autoencoder
use_math: true
comments: true
---

#### ë…¼ë¬¸ ì¶œì²˜: [Linear Variational Autoencoder for Top-N Recommendation](https://ieeexplore.ieee.org/document/9760352)


ì´ë²ˆ í¬ìŠ¤íŒ…ì€ `Mult-VAE` ([ë…¼ë¬¸ ë¦¬ë·°](https://hyxxnii.github.io/recommender%20system/2022/09/14/paper-review-VAE/)) ì˜ ì„ í˜• ë²„ì „ì¸ Linear VAEë¥¼ ì œì•ˆí•œ ë…¼ë¬¸ì„ ì½ê³  ì •ë¦¬í•œ ê²ƒì´ë‹¤.


<br>

## Abstract

- VAEì™€ Mult-VAEëŠ” multinomial likelihoodì™€ ELBOì˜ KL divergence termì— ëŒ€í•œ ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„° $\beta$ë¥¼ ë„ì…í•˜ì—¬ í° ì„±ëŠ¥ì„ ì´ëŒì—ˆë‹¤
- ê·¸ëŸ¬ë‚˜ Mult-VAEëŠ” **ë¹„ì„ í˜• ì‹ ê²½ë§ì„ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¡œ ì‚¬ìš©**í•˜ì—¬ ìœ ì €-ì•„ì´í…œ ìƒí˜¸ ì‘ìš© ë°ì´í„°ë¥¼ ì¸ì½”ë”©í•˜ê³  ì¬êµ¬ì„± â‡’ **ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ì €í•˜ì‹œí‚¤ê¸° ë•Œë¬¸ì— sparse ë°ì´í„° ì…‹ì—ì„œ ë¶ˆí•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì¦ëª…**
- ë˜í•œ VAE ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ ë°©ë²•ì˜ ëŒ€ë¶€ë¶„ì˜ ë³€í˜•ì—ì„œëŠ” **ë¹„ì •ê·œí™”ëœ ìœ ì €-ì•„ì´í…œ ìƒí˜¸ ì‘ìš© ë°ì´í„°**ë¥¼ ì‚¬ìš© â‡’ **ìƒí˜¸ ì‘ìš© ë°ì´í„°ì˜ í•™ìŠµ ê³¼ì •ì„ ë°©í•´í•  ê²ƒì´ë‹¤**
- **ë³¸ ë…¼ë¬¸ì—ì„œëŠ” implicit feedbackì—ì„œ ìœ ì €-ì•„ì´í…œ ìƒí˜¸ ì‘ìš© ë°ì´í„°ì— ëŒ€í•œ ì¶”ê°€ ì •ê·œí™”ë¥¼ ê³ ë ¤í•˜ëŠ” Mult-VAEì˜ ì„ í˜• ë²„ì „ì¸ LVA(Linear Variaitional Autoencoder)ë¥¼ ì œì•ˆí•œë‹¤**

<br>

## I. INTRODUCTION

- ë¹„ì„ í˜• ì‹ ê²½ë§ì„ ì´ìš©í•œ ê¸°ì¡´ VAEì™€ ê·¸ì— ëŒ€í•œ ë§ì€ ë³€í˜• ëª¨ë¸ â‡’ **sparse datasetì˜ ì¶”ì²œì‹œìŠ¤í…œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° í•„ìš”í•œê°€ë¼ëŠ” ì§ˆë¬¸**
- ì €ìë“¤ì´ Mult-VAEì˜ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ single-layer ì„ í˜• êµ¬ì¡°ë¡œ ë‹¨ìˆœí™”í–ˆì„ ë•Œ sparse datasetì—ì„œ ì„±ëŠ¥ì´ ë” í–¥ìƒëœë‹¤ëŠ” ê²ƒì„ ë°œê²¬ (in Table 3) â‡’ ë¹„ì„ í˜• ì¸ì½”ë”, ë””ì½”ë”ê°€ ì˜¤íˆë ¤ ì„±ëŠ¥ ë–¨ì–´ëœ¨ë¦°ë‹¤

â‡’ ìƒì„± ëª¨ë¸ì´ê³  ì›ë˜ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•´ ì„¤ê³„ëœ VAEê°€ **sparseí•œ ìœ ì €-ì•„ì´í…œ ìƒí˜¸ ì‘ìš© ë°ì´í„°ì— ì¸ì½”ë”ì™€ ë””ì½”ë”ë¡œ ë³µì¡í•œ ë¹„ì„ í˜• ì‹ ê²½ë§ì„ ì‚¬ìš©í•  ê²½ìš° CF taskì— ë§ì§€ ì•ŠëŠ”ë‹¤ê³  ì£¼ì¥!**

**ğŸ“Â Motivation**

- LightGCN(Graph Convolution Network): GCNì—ì„œ ìƒì†ëœ feature transformationê³¼ ë¹„ì„ í˜• í™œì„±í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ë•Œ ë” ë‚˜ìœ ê²°ê³¼ë¥¼ ì–»ëŠ”ë‹¤ â‡’ sparseí•œ ìœ ì €-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë³µì¡í•œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ì €í•˜ë˜ê³  í•™ìŠµ í”„ë¡œì„¸ìŠ¤ê°€ ì™œê³¡ë  ìˆ˜ ìˆë‹¤
    - GCNì˜ 2ê°€ì§€ íŠ¹ì§•, feature transformationê³¼ nonlinear activationë“¤ì´ í˜‘ì—…í•„í„°ë§ ì„±ëŠ¥ì— í¬ê²Œ ê¸°ì—¬í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ í™•ì¸ (ì˜¤íˆë ¤ ì´ë“¤ì„ ì¶”ê°€í–ˆì„ ë•Œ í•™ìŠµì´ ë” ì–´ë ¤ì›Œì§€ê³  ì¶”ì²œ ì„±ëŠ¥ì´ ë” ë–¨ì–´ì§€ëŠ” ê²½ìš°ë„ ìˆì—ˆìŒ)
    - ê·¸ë˜ì„œ GCNì„ ë” ê°„ì†Œí™”í•´ì„œ user-item interaction graphì—ì„œ ì„ í˜•ì ìœ¼ë¡œ ì „íŒŒ
    
    **â‡’ VAEë„ í›¨ì”¬ ë‹¨ìˆœí•˜ê²Œ í•™ìŠµí•˜ë„ë¡ ë™ê¸° ë¶€ì—¬**


<br>

ğŸ“ **LVA(Linear Variational Autoencoder)**

ë¹„ì„ í˜• í™œì„±í•¨ìˆ˜ê°€ ì—†ëŠ” one-layer linear structure(= one-layer MLP)ë¥¼ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¡œ ì œì•ˆ
  - ì¸ì½”ë”ì™€ ë””ì½”ë”ê°€ linear regression ëª¨ë¸ê³¼ ìœ ì‚¬
  - ë‹¤ë¥¸ linear ë°©ì‹ë„ ë” ì¢‹ì€ ì¶”ì²œ ì„±ëŠ¥ì— ì“°ì¼ ìˆ˜ ìˆì§€ë§Œ (e.g., pure matrix multiplication without extra bias) future workë¡œ ë‚¨ê²¼ë‹¤
  - **ì´ëŸ¬í•œ ê°„ë‹¨í•œ ì„ í˜• ì¸ì½”ë”ì™€ ë””ì½”ë”ëŠ” posterior collapse ë¬¸ì œë¥¼ ì™„í™”í•˜ê³  ìƒí˜¸ ì‘ìš© ë°ì´í„°ë¥¼ ë” ì˜ ë§ì¶œ ìˆ˜ ìˆë„ë¡í•˜ë©°, ranking accuracyë¥¼ ë” ë†’ì¸ë‹¤** (ì´í›„ ì‹¤í—˜ì—ì„œ ë³´ì—¬ì¤Œ)
    

### Main contributions

- Top-N recommendationì„ ìœ„í•´ **ì„ í˜• ì¸ì½”ë”ì™€ ë””ì½”ë”**ë¥¼ ê°€ì§„ ë‹¨ìˆœí™”ëœ VAE ê¸°ë°˜ ëª¨ë¸ LVAë¥¼ ì œì•ˆ
- LVAì˜ **ì„ í˜• êµ¬ì¡°ì— ë§ì¶˜** ìœ ì €-ì•„ì´í…œ ìƒí˜¸ ì‘ìš© ë°ì´í„°ì— ì‚¬ìš©ìì™€ í•­ëª©ì— ëŒ€í•œ **ì¶”ê°€ ì •ê·œí™”ë¥¼ ì±„íƒ**í•  ê²ƒ
- LVAê°€ LightGCN ë° ë‹¤ë¥¸ ë³µì¡í•œ VAE ê¸°ë°˜ ë³€í˜• ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ **ë” ë‚˜ì€ ë˜ëŠ” ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥** ë‹¬ì„±
- í–¥í›„ íš¨ê³¼ì ì¸ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì„ ë” ì˜ ì„¤ê³„í•˜ê¸° ìœ„í•´ **ì‹¤í—˜ ë° ì´ë¡ ì  ë¶„ì„** ì œì‹œ

<br>

# II. PRELIMINARY

- notations, ë¬¸ì œ ì •ì˜, Mult-VAEì˜ ê¸°ë³¸ ì†Œê°œ


<br>


### A. notations

![Untitled](https://user-images.githubusercontent.com/48899040/215703919-f633471a-01b9-4e07-9aaa-5ac583d2d01d.png)


<br>

### B. Problem Definition

- Sparse binary implicit feedback settingê°€ ì£¼ì–´ì§ˆ ë•Œ
- personalized recommender that can recommend the top-N items

<br>

### C. Basics of Mult-VAE

![Untitled 1](https://user-images.githubusercontent.com/48899040/215704121-8a9b5534-fc13-40e3-8fb1-0e5b60dbe54d.png)

![Untitled 2](https://user-images.githubusercontent.com/48899040/215704129-8172d8a3-3401-4475-b04d-4cd90229193b.png)


<br>

# III. LINEAR VARIATIONAL AUTOENCODER

## A. Linear Encoder and Decoder

- linear transformationì„ ê°€ì§„ ì„ í˜• ë””ì½”ë”
    
    ![Untitled 3](https://user-images.githubusercontent.com/48899040/215704131-82ae1f83-ca2f-431c-be07-e4337d2e410d.png)
    
    - $W_\theta\in \mathbb R^{K\times|I|}$, $b_\theta \in \mathbb R^{|I|}$: ë””ì½”ë”ì˜ weightì™€ bias, $K$ëŠ” latent dimension
    - $z_u\in \mathbb R^K$: ìœ ì € $u$ì˜ latent representation
  
- ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ìœ ì €ì™€ ì•„ì´í…œ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ëª¨ë¸ë§í•  ë•Œ ë‹¨ìˆœí•œ dot productê°€ ë³µì¡í•œ MLPë³´ë‹¤ ë‚«ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆê¸°ì— íƒ€ë‹¹í•˜ë‹¤
    - MLPëŠ” ì¶©ë¶„í•œ hidden statesë¥¼ ê°€ì§€ê³  ìˆëŠ” compact setì—ì„œ ëª¨ë“  ì—°ì† í•¨ìˆ˜ë¥¼ ê·¼ì‚¬í•  ìˆ˜ ìˆëŠ” universal approximator â‡’ MLPë¡œ dot productë¥¼ ê·¼ì‚¬í•˜ëŠ” ê²ƒì€ í° ëª¨ë¸ ìš©ëŸ‰ê³¼ í›ˆë ¨ ì…‹ì´ í•„ìš”í•˜ê¸°ë•Œë¬¸ì— ì–´ë µë‹¤

- ì¸ì½”ë”: variational distribution $q_\phi(z_u|x_u)$ì˜ í‰ê· ê³¼ ë¶„ì‚°ì„ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ë‘ í•¨ìˆ˜ë¡œ êµ¬ì„±ë¨
    
    ![Untitled 4](https://user-images.githubusercontent.com/48899040/215704136-25ce1952-a58c-445d-96e0-4d3148ce1059.png)
    
    - $W_\mu\in \mathbb R^{|I|\times K}$, $b_\mu \in \mathbb R^{K}$: mean functionì˜ weightì™€ bias
    - $W_\sigma\in \mathbb R^{|I|\times K}$, $b_\sigma \in \mathbb R^{K}$: variance functionì˜ weightì™€ bias

![Untitled 5](https://user-images.githubusercontent.com/48899040/215704140-d2cf02de-0e01-4a7a-9056-524648cb4a58.png)

![Untitled 6](https://user-images.githubusercontent.com/48899040/215704143-3cc61c81-0f0b-49f3-9323-22f7d64e2809.png)

- ELBOì‹ì€ ê¸°ì¡´ Mult-VAEì™€ ë™ì¼
    
    ![Untitled 7](https://user-images.githubusercontent.com/48899040/215704146-2a197110-2ee2-4d2c-9d37-88863a93b0da.png)

    - ì°¨ì´ì : variational distribution $q_\phi(z_u|x_u)$ì˜ íŒŒë¼ë¯¸í„°ê°€ (í‰ê· , ë¶„ì‚°) ì‹ (5)ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°ëœë‹¤ëŠ” ê²ƒ
    - ë‚˜ë¨¸ì§€ í•™ìŠµê³¼ì •ë„ ë™ì¼
    

<br>

## B. Normalization

- ìœ ì €-ì•„ì´í…œ ìƒí˜¸ì‘ìš© matrixì˜ í–‰, ì—´ ë²¡í„° ëª¨ë‘ì— ëŒ€í•œ ì •ê·œí™” ì¶”ê°€
    - ì—´ ë²¡í„°ì— ëŒ€í•œ ì¶”ê°€ ì •ê·œí™”ë¥¼ ì¶”ê°€í•˜ëŠ” ì´ìœ : í–‰ë ¬ $X$ì˜ itemì˜ ì¸ê¸°ê°€ ì¶”ì²œì‹œìŠ¤í…œ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆê¸° ë•Œë¬¸ â‡’ ì§ê´€ì ìœ¼ë¡œ ì¸ê¸° ì•„ì´í…œì´ ê³¼ë„í•˜ê²Œ ì¶”ì²œë˜ê³ , ëœ ì¸ê¸° ìˆëŠ” ì•„ì´í…œì€ ê±°ì˜ ì¶”ì²œë˜ì§€ ì•ŠëŠ” ë¬¸ì œë¥¼ í”¼í•  ìˆ˜ ìˆë‹¤ (fairnessë¥¼ ê³ ë ¤)
- denote
    - all one column vector: $1$ ($1$ can be any dimension)
    - The user degree matrix: $D_U=Diag(X\cdot1)$
    - The item degree matrix: $D_I=Diag(1^T\cdot X)$
- ì •ê·œí™”ëœ user-item ìƒí˜¸ì‘ìš© matrix
    
    ![Untitled 8](https://user-images.githubusercontent.com/48899040/215704153-3541f916-be02-4219-bd38-85375cd2755f.png)
    
    - ìœ ì €-ì•„ì´í…œ ìƒí˜¸ ì‘ìš© matrixì˜ í–‰ê³¼ ì—´ ë²¡í„° ëª¨ë‘ì— ì •ê·œí™”ë¥¼ ì¶”ê°€í•˜ë©´ Section $IV-D$ì— ë‚˜íƒ€ë‚œ ë°”ì™€ ê°™ì´ LDAê°€ í›ˆë ¨ ë°ì´í„°ì— ë” ì˜ ì í•©í•˜ê²Œ ëœë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤
    

<br>

## C. Interpretation

- ì„ í˜• ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ì‚¬ìš©í•œ LVAì˜ íš¨ê³¼ë¥¼ ê°„ëµí•˜ê²Œ ì œì‹œ

1. ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ë‹¨ìˆœí•œ ì„ í˜•êµ¬ì¡° â†’ ì´ë¯¸ì§€ ë°ì´í„°ë³´ë‹¤ ë¹„êµì  ë” ë‹¨ìˆœí•œ ìœ ì €-ì•„ì´í…œ ìƒí˜¸ ì‘ìš© matrixì— ë” ì˜ë§ëŠ”ë‹¤
    - [15]ì—ì„œ ì–¸ê¸‰í•œ ë°”ì™€ ê°™ì´, linear VAEì˜ ELBOëŠ” local maixmaë¥¼ introduceí•˜ì§€ ì•Šê³ , variational inferenceë¥¼ í†µí•´ í›ˆë ¨í•˜ë©´ ì£¼ì„±ë¶„ ë°©í–¥ì— í•´ë‹¹í•˜ëŠ” identifiable global maximumì„ recoverí•œë‹¤
    - As is mentioned in [15], the ELBO of linear VAE does not introduce local maxima and training a linear VAE with variational inference recovers an identifiable global maximum corresponding to the principle component directions.
    
    **â‡’ ì¦‰, linear VAEëŠ” VAEì—ì„œì˜ posterior collapse ë¬¸ì œë¥¼ ì™„í™”í•  ìˆ˜ ìˆë‹¤**
    
2. LVAëŠ” one-layer LightGCNê³¼ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆë‹¤
    - ì¸ì½”ë”ì˜ weight í–‰ê³¼ ë””ì½”ë”ì˜ weight ì—´ì„ ë‘ ì„¸íŠ¸ì˜ ì•„ì´í…œ ì„ë² ë”©(two sets of item embeddings)ìœ¼ë¡œ ê°„ì£¼í•  ë•Œ
    - ì¸ì½”ë”ëŠ” one-layer graph convolution, ë””ì½”ë”ëŠ” ê°ê°ì˜ ìœ ì €ì˜ ì•„ì´í…œ ì„ í˜¸ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” dot productì— í•´ë‹¹
    - ì°¨ì´ì : LVAì˜ ì¸ì½”ë”ì™€ ë””ì½”ë”ì—ëŠ” biases termì´ ìˆê³ , LDAì—ëŠ” **self-connectionì´ ì—†ë‹¤**ëŠ” ê²ƒ
        
        **â‡’ LVAê°€ ì´ì›ƒì„ í™œìš©í•´ ìœ ì €ì˜ representationsì„ ê°•í™”í•˜ê³ , ë‹¨ìˆœí•˜ì§€ë§Œ íš¨ê³¼ì ì¸ dot productë¥¼ ìœ ì €ì™€ ì•„ì´í…œì˜ ìƒí˜¸ì‘ìš© functionìœ¼ë¡œ ì ìš©í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ„**
        
    - ë˜í•œ LVAì— ì‚¬ìš©ëœ ë² ì´ì§€ì•ˆ ì¶”ë¡ ì€ sparse ë°ì´í„°ì…‹ì— ë” ì í•©í•˜ê²Œ ë§Œë“ ë‹¤

<br>

# IV. EXPERIMENTS

## A. Experimental Settings

*1) Datasets and Evaluation Metrics*

![Untitled 9](https://user-images.githubusercontent.com/48899040/215704159-43c0d6ad-325a-48c5-a891-ce5d6cf5689e.png)

- evaluation metrics: recall@20, ndcg@20

*2) Baseline Methods*

- 2ê°œì˜ ì „í†µì ì¸ ì¶”ì²œì‹œìŠ¤í…œ ë°©ë²• â‡’ **LightGCN, variants of VAE-based recommendation methods**
    - LightGCN
        - NGCF (Neural Graph Collaborative Filtering) ë³´ë‹¤ ë” ê°œì„ ëœ ì„±ëŠ¥
        - NGCFëŠ” NCFì™€ ê°™ì€ ë§ì€ ì‹ ê²½ë§ ì¶”ì²œ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¨
    - VAE-based variants
        - **Mult-VAE, EVCF(Enhancing VAEs for Collaborative Filtering), RecVAE**
        
- The baseline method
    - Item-Pop
    - MF-BRP
    - LightGCN
    - Mult-VAE
    - EVCF
    - RecVAE
    

*3) Hyperparameter Settings*

- ê³µì •í•œ ë¹„êµ â‡’ LightGCNì˜ embedding size, LVAì˜ latent dimensionëŠ” 64ë¡œ ê³ ì •
- Mult-VAE: 600 â†’ 200 â†’ 600 (ê¸°ì¡´ ëª¨ë¸ ì•„í‚¤í…ì³)
- RecVAEì— ë”°ë¼ ìš°ë¦¬ì˜ ëª¨ë¸ë„ hidden dimension=600, latent dimension=200ìœ¼ë¡œ ì„¤ì •
- Adam optimizer
- learning rates: 0.001
    - RecVAE, EVCF: $5\cdot 10^-4$

<br>

## B. Performance Comparison

![Untitled 10](https://user-images.githubusercontent.com/48899040/215704165-200ca33f-fedf-453c-9e10-3e2996a523f5.png)

- íŠ¹íˆ Mult-VAE ì„±ëŠ¥ë³´ë‹¤ í° ê°œì„ ì„ ë³´ì˜€ìŒ
    - recall@20ì— ëŒ€í•´ì„  15.3%, ndcg@20ì— ëŒ€í•´ì„  18.0%
- Yelp2018, Amazon-Book, Video-Games ë°ì´í„°ì…‹ì— ëŒ€í•´ LightGCNë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥
    
    **â‡’ sparse ë°ì´í„°ì…‹ê³¼ linear encoder/decoder, normalization on the user-item interaction matrixì—ì„œ LVAì˜ íš¨ê³¼ë¥¼ ì¦ëª…í•œ ê²°ê³¼**
    
<br>

## C. Ablation Study

- LVA-norm: ì œì•ˆëœ ì •ê·œí™”ë¥¼ ìœ ì €-ì•„ì´í…œ matrixì´ ì•„ë‹Œ, **ìœ ì €ì— ëŒ€í•´ì„œë§Œ ì •ê·œí™”ë¥¼ ì ìš©í•œ ë³€í˜•**
    - ë¹„ì„ í˜• êµ¬ì¡°ë¥¼ ê°€ì§„ VAE ê¸°ë°˜ ë³€í˜• ëª¨ë¸ì„ ëŠ¥ê°€
- LVAì˜ ì„±ëŠ¥ì€ LVA-norm ë³´ë‹¤ ë”ìš± í–¥ìƒëœ í¼í¬ë¨¼ìŠ¤ â‡’ ìœ ì €ì™€ ì•„ì´í…œ ëª¨ë‘ì— ëŒ€í•´ ì •ê·œí™”í•˜ëŠ” ê²ƒì˜ íš¨ê³¼ ê²€ì¦

<br>

## D. Discussion

![Untitled 11](https://user-images.githubusercontent.com/48899040/215704175-f97a68c6-3381-4c8b-a36f-1fbe0c635227.png)

- reconstruction errorì™€ KL divergenceì— ê´€í•œ í•™ìŠµ ì ˆì°¨ ê·¸ë˜í”„
- LVAê°€ ë” ë‚®ì€ reconstruction error â‡’ training dataë¥¼ ë” ì˜ fití•  ìˆ˜ ìˆê³ , local minimaë¥¼ í”¼í•  ìˆ˜ ìˆë‹¤
- ë” ë†’ì€ KLD ê°’ â‡’ posterior collapseë¥¼ ê²ªì„ ê°€ëŠ¥ì„±ì´ ë” ë‚®ë‹¤
    - prior ë¶„í¬ì™€ inference ë¶„í¬ê°€ ìµœëŒ€í•œ ì¼ì¹˜í•˜ë„ë¡ KLD ê°’ì„ minimize *(â‡’ ê·¼ë° ê°œì¸ì ìœ¼ë¡œ ì´ë ‡ê²Œ í•´ì„í•˜ëŠ” ê²ƒì€ ìœ„í—˜í•œ ë°œì–¸ìœ¼ë¡œ ë³´ì„..)*
    

![Untitled 12](https://user-images.githubusercontent.com/48899040/215704182-81a2ca2d-0ef0-45a1-9a57-dc2b61a39a08.png)

- ëª¨ë“  test userì— ëŒ€í•´ top 20ì— ì¶”ì²œë˜ëŠ” ì•„ì´í…œ ë¹ˆë„ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸´ ê·¸ë˜í”„
- LVAê°€ LVA-normë³´ë‹¤ ë” ìì£¼ long-tail ì•„ì´í…œì„ ì¶”ì²œí•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤
    - ì•„ì´í…œì— ëŒ€í•œ ì¶”ê°€ ì •ê·œí™”ì˜ íš¨ê³¼ ì…ì¦

<br>

# V. RELATED WORKS
ìƒëµ

## *A. VAE-based CF methods*

## *B. Latent Factor models*

<br>

# VI. CONCLUSION

- Mult-VAEì˜ ë‹¨ìˆœí™”ëœ ë²„ì „ ì œì•ˆ â‡’ LVA
- sparseí•œ ìƒí˜¸ ì‘ìš© ë°ì´í„°ë¥¼ í•™ìŠµí•˜ëŠ” ë° ë„ì›€ì´ ë˜ë„ë¡ ìœ ì €ì™€ ì•„ì´í…œ ëª¨ë‘ì—ì„œ user-item interaction matrixì— ëŒ€í•œ ì •ê·œí™” ì‚¬ìš© ì œì•ˆ